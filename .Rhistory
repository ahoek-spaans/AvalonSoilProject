flagNums <- match(flag_cols, names(error_df))
# file 3: error_output/pub_flags - this file needs the flag column
select(error_df, colNums, flagNums) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_pubFlags.csv"),
row.names = FALSE,na='', fileEncoding='UTF-8') # pub_flags (error_output)
colNums2 <- match(pub_cols, names(golden_df)) # feed column positions for golden_output
# file 4: golden_output
select(golden_df,colNums2) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_pubNoFlags.csv"),
row.names = FALSE,na='',fileEncoding='UTF-8') # pub_noFlags (golden_output)
}
gen_outputFiles(golden_df = pubFieldData,
error_df = inFieldData,
pub_cols = c("siteID","plotID","eventID"),
added_cols = c("X","eventID","duplicatePlotIDTrapIDCollectDateQF"),
flag_cols = c("duplicatePlotIDTrapIDCollectDateQF"),
fileName = "beetles")
gen_outputFiles <- function(golden_df,error_df, pub_cols, added_cols, flag_cols, fileName){
browser()
require(dplyr)
# for all columns - input files that 1) have errors (errorInput) and 2) have no errors (goldenInput)
# file 1: dump flagging column - this needs to dump the added eventID and flag columns
addedNum <- match(flag_cols, names(error_df)) # columns to be removed from input
select(error_df, -(addedNum)) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_errorInput.csv"),
row.names = FALSE,na='', fileEncoding='UTF-8') # error_input
# file 2: golden_input, no error rows, all columns including flags 0 this needs to dump added columns
select(golden_df, -(addedNum)) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_goldenInput.csv"),
row.names = FALSE,na='',fileEncoding='UTF-8') # golden_input
# for specific columns
colNums <- match(pub_cols, names(error_df)) # feed column positions for error_output
flagNums <- match(flag_cols, names(error_df))
# file 3: error_output/pub_flags - this file needs the flag column
select(error_df, colNums, flagNums) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_pubFlags.csv"),
row.names = FALSE,na='', fileEncoding='UTF-8') # pub_flags (error_output)
colNums2 <- match(pub_cols, names(golden_df)) # feed column positions for golden_output
# file 4: golden_output
select(golden_df,colNums2) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_pubNoFlags.csv"),
row.names = FALSE,na='',fileEncoding='UTF-8') # pub_noFlags (golden_output)
}
gen_outputFiles(golden_df = pubFieldData,
error_df = inFieldData,
pub_cols = c("siteID","plotID","eventID"),
added_cols = c("X","eventID","duplicatePlotIDTrapIDCollectDateQF"),
flag_cols = c("duplicatePlotIDTrapIDCollectDateQF"),
fileName = "beetles")
addedNum
colNums
flagNums
# error_filter(flag), golden_filter(flag)
gen_outputFiles <- function(golden_df,error_df, pub_cols, added_cols, flag_cols, fileName){
browser()
require(dplyr)
# for all columns - input files that 1) have errors (errorInput) and 2) have no errors (goldenInput)
# file 1: dump flagging column - this needs to dump the added eventID and flag columns
addedNum <- match(flag_cols, names(error_df)) # columns to be removed from input
select(error_df, -(addedNum)) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_errorInput.csv"),
row.names = FALSE,na='', fileEncoding='UTF-8') # error_input
# file 2: golden_input, no error rows, all columns except for added columns
select(golden_df, -(addedNum)) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_goldenInput.csv"),
row.names = FALSE,na='',fileEncoding='UTF-8') # golden_input
# for specific columns
colNums <- match(pub_cols, names(error_df)) # feed column positions for error_output
flagNums <- match(flag_cols, names(error_df))
# file 3: error_output/pub_flags - this file needs the flag column
select(error_df, colNums, flagNums) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_pubFlags.csv"),
row.names = FALSE,na='', fileEncoding='UTF-8') # pub_flags (error_output)
colNums2 <- match(pub_cols, names(golden_df)) # feed column positions for golden_output
# file 4: golden_output
select(golden_df,colNums2) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_pubNoFlags.csv"),
row.names = FALSE,na='',fileEncoding='UTF-8') # pub_noFlags (golden_output)
}
library(dplyr)
names(pubFieldData)
# pub_cols <- c("domainID","siteID","plotID") # columns to pass
# colNums <- match(pub_cols, names(pubFieldData)) # feed column positions as integers for select()
# select(pubFieldData, colNums) # try select
gen_outputFiles(golden_df = pubFieldData,
error_df = inFieldData,
pub_cols = c("siteID","plotID","eventID"),
added_cols = c("X","eventID","duplicatePlotIDTrapIDCollectDateQF"),
flag_cols = c("duplicatePlotIDTrapIDCollectDateQF"),
fileName = "beetles")
addedNum
ls()
names(error_df)
names(golden_df)
colNums
flagNums
addedNum
colNums2
pub_cols <- c("domainID","siteID","plotID") # columns to pass
colNums <- match(pub_cols, names(pubFieldData)) # feed column positions as integers for select()
select(pubFieldData, colNums) # try select
select(pubFieldData, -colNums) # try select
select(pubFieldData, colNums) # try select
select(pubFieldData, -colNums) # try select
select(pubFieldData, colNums) # try select
select(pubFieldData, (colNums)) # try select
select(pubFieldData, -(colNums)) # try select
wdir <- 'C:/Users/cflagg/Documents/Test/atbd_output_test'
myPathToGraphics <- paste(wdir,'graphics', sep='/')
myPathToData <- paste(wdir,'data', sep='/')
myPathToCIFiles <- paste(myPathToData, 'CI_files', sep='/')
inFieldData <- read.csv(paste(myPathToData, 'ExampleBeetle_FieldData.csv', sep='/'), stringsAsFactors=FALSE)
inFieldData <- rbind(inFieldData[1,],inFieldData) # No duplicates exist, need to introduce an error to the input dataset
pubFieldData <- gen_concatenatedVal(df=inFieldData, cols=c("plotID", "trapID", "collectDate"), separator=".", newColName="eventID")
```
```{r eventIDout, anchor="Table", echo=FALSE}
gen_exampleTable(df=pubFieldData, startRow=1, endRow=5, cols=c("plotID", "trapID", "collectDate", "eventID"), cap="EventID output data")
## run next step on object=pubFieldData, not myFieldData
## write.csv after running all algorithm steps
```
2a. Flag duplicate rows for error_out file (inFieldData)
[//]: ## FILE 2: error_out
```{r}
# flag duplicate rows
inFieldData <- flag_dups(pubFieldData,cols=c("plotID", "trapID", "collectDate"))
```
[//]: ## inFieldData file should not have rows removed
2b. Remove Duplicate rows for golden_in/out files (pubFieldData)
```{r duplicateIn, anchor="Table", echo=FALSE, }
```
gen_exampleTable(df=pubFieldData, startRow=1, endRow=5, cols=c("plotID", "trapID", "collectDate"), cap="eventID input data")
Duplicate rows are identified as those that have the same data in  **plotID** AND **trapID** AND **collectDate** (`r figr('duplicateIn', prefix=TRUE, link=TRUE )`).
## FILE 3: golden_in
```{r duplicateOut, anchor="Table", echo=FALSE}
pubFieldData <- rem_dups(df=pubFieldData, cols=c("plotID", "trapID", "collectDate"))
# error_filter(flag), golden_filter(flag)
gen_outputFiles <- function(golden_df,error_df, pub_cols, added_cols, flag_cols, fileName){
browser()
require(dplyr)
# for all columns - input files that 1) have errors (errorInput) and 2) have no errors (goldenInput)
# file 1: dump flagging column - this needs to dump the added eventID and flag columns
addedNum <- match(flag_cols, names(error_df)) # columns to be removed from input
select(error_df, -(addedNum)) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_errorInput.csv"),
row.names = FALSE,na='', fileEncoding='UTF-8') # error_input
# file 2: golden_input, no error rows, all columns except for added columns
select(golden_df, -(addedNum)) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_goldenInput.csv"),
row.names = FALSE,na='',fileEncoding='UTF-8') # golden_input
# for specific columns
colNums <- match(pub_cols, names(error_df)) # feed column positions for error_output
flagNums <- match(flag_cols, names(error_df))
# file 3: error_output/pub_flags - this file needs the flag column
select(error_df, colNums, flagNums) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_pubFlags.csv"),
row.names = FALSE,na='', fileEncoding='UTF-8') # pub_flags (error_output)
colNums2 <- match(pub_cols, names(golden_df)) # feed column positions for golden_output
# file 4: golden_output
select(golden_df,colNums2) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_pubNoFlags.csv"),
row.names = FALSE,na='',fileEncoding='UTF-8') # pub_noFlags (golden_output)
}
# error_filter(flag), golden_filter(flag)
gen_outputFiles <- function(golden_df,error_df, pub_cols, added_cols, flag_cols, fileName){
browser()
require(dplyr)
# for all columns - input files that 1) have errors (errorInput) and 2) have no errors (goldenInput)
# file 1: dump flagging column - this needs to dump the added eventID and flag columns
addedNum <- match(flag_cols, names(error_df)) # columns to be removed from input
select(error_df, -(addedNum,added_cols)) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_errorInput.csv"),
row.names = FALSE,na='', fileEncoding='UTF-8') # error_input
# file 2: golden_input, no error rows, all columns except for added columns
select(golden_df, -(addedNum, added_cols)) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_goldenInput.csv"),
row.names = FALSE,na='',fileEncoding='UTF-8') # golden_input
# for specific columns
colNums <- match(pub_cols, names(error_df)) # feed column positions for error_output
flagNums <- match(flag_cols, names(error_df))
# file 3: error_output/pub_flags - this file needs the flag column
select(error_df, colNums, flagNums) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_pubFlags.csv"),
row.names = FALSE,na='', fileEncoding='UTF-8') # pub_flags (error_output)
colNums2 <- match(pub_cols, names(golden_df)) # feed column positions for golden_output
# file 4: golden_output
select(golden_df,colNums2) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_pubNoFlags.csv"),
row.names = FALSE,na='',fileEncoding='UTF-8') # pub_noFlags (golden_output)
}
gen_outputFiles <- function(golden_df,error_df, pub_cols, added_cols, flag_cols, fileName){
browser()
require(dplyr)
# for all columns - input files that 1) have errors (errorInput) and 2) have no errors (goldenInput)
# file 1: dump flagging column - this needs to dump the added eventID and flag columns
addedNum <- match(flag_cols, names(error_df)) # columns to be removed from input
select(error_df, -(addedNum,added_cols)) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_errorInput.csv"),
row.names = FALSE,na='', fileEncoding='UTF-8') # error_input
# file 2: golden_input, no error rows, all columns except for added columns
select(golden_df, -(addedNum, added_cols)) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_goldenInput.csv"),
row.names = FALSE,na='',fileEncoding='UTF-8') # golden_input
# for specific columns
colNums <- match(pub_cols, names(error_df)) # feed column positions for error_output
flagNums <- match(flag_cols, names(error_df))
# file 3: error_output/pub_flags - this file needs the flag column
select(error_df, colNums, flagNums) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_pubFlags.csv"),
row.names = FALSE,na='', fileEncoding='UTF-8') # pub_flags (error_output)
colNums2 <- match(pub_cols, names(golden_df)) # feed column positions for golden_output
# file 4: golden_output
select(golden_df,colNums2) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_pubNoFlags.csv"),
row.names = FALSE,na='',fileEncoding='UTF-8') # pub_noFlags (golden_output)
}
# error_filter(flag), golden_filter(flag)
gen_outputFiles <- function(golden_df,error_df, pub_cols, added_cols, flag_cols, fileName){
browser()
require(dplyr)
# for all columns - input files that 1) have errors (errorInput) and 2) have no errors (goldenInput)
# file 1: dump flagging column - this needs to dump the added eventID and flag columns
addedNum <- match(added_cols, names(error_df)) # columns to be removed from input
colNums <- match(pub_cols, names(error_df)) # feed pub column column positions for error_output
flagNums <- match(flag_cols, names(error_df)) # column with flags
colNums2 <- match(pub_cols, names(golden_df)) # feed pub column positions for golden_output
select(error_df, -addedNum, -flagNums) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_errorInput.csv"),
row.names = FALSE,na='', fileEncoding='UTF-8') # error_input
# file 2: golden_input, no error rows, all columns except for added columns
select(golden_df, -addedNum, -flagNums) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_goldenInput.csv"),
row.names = FALSE,na='',fileEncoding='UTF-8') # golden_input
# for specific columns
# file 3: error_output/pub_flags - this file needs the flag column
select(error_df, colNums, flagNums) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_pubFlags.csv"),
row.names = FALSE,na='', fileEncoding='UTF-8') # pub_flags (error_output)
# file 4: golden_output
select(golden_df,colNums2) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_pubNoFlags.csv"),
row.names = FALSE,na='',fileEncoding='UTF-8') # pub_noFlags (golden_output)
}
gen_outputFiles(golden_df = pubFieldData,
error_df = inFieldData,
pub_cols = c("siteID","plotID","eventID"),
added_cols = c("X","eventID","duplicatePlotIDTrapIDCollectDateQF"),
flag_cols = c("duplicatePlotIDTrapIDCollectDateQF"),
fileName = "beetles")
# error_filter(flag), golden_filter(flag)
gen_outputFiles <- function(golden_df,error_df, pub_cols, added_cols, flag_cols, fileName){
browser()
require(dplyr)
# these variables convert column names into integer positions
addedNum <- match(added_cols, names(error_df)) # columns to be removed from input
colNums <- match(pub_cols, names(error_df)) # feed pub column column positions for error_output
flagNums <- match(flag_cols, names(error_df)) # column with flags
colNums2 <- match(pub_cols, names(golden_df)) # feed pub column positions for golden_output
# for all columns - input files that 1) have errors (errorInput) and 2) have no errors (goldenInput)
# file 1: dump flagging column - this needs to dump the added eventID and flag columns
select(error_df, -addedNum) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_errorInput.csv"),
row.names = FALSE,na='', fileEncoding='UTF-8') # error_input
# file 2: golden_input, no error rows, all columns except for added columns
select(golden_df, -addedNum) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_goldenInput.csv"),
row.names = FALSE,na='',fileEncoding='UTF-8') # golden_input
# for specific columns
# file 3: error_output/pub_flags - this file needs the flag column
select(error_df, colNums, flagNums) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_pubFlags.csv"),
row.names = FALSE,na='', fileEncoding='UTF-8') # pub_flags (error_output)
# file 4: golden_output
select(golden_df,colNums2) %>% write.csv(file = paste(myPathToCIFiles,fileName,"_pubNoFlags.csv"),
row.names = FALSE,na='',fileEncoding='UTF-8') # pub_noFlags (golden_output)
}
library(dplyr)
names(pubFieldData)
pub_cols <- c("domainID","siteID","plotID") # columns to pass
colNums <- match(pub_cols, names(pubFieldData)) # feed column positions as integers for select()
select(pubFieldData, -(colNums)) # try select
gen_outputFiles(golden_df = pubFieldData,
error_df = inFieldData,
pub_cols = c("siteID","plotID","eventID"),
added_cols = c("X","eventID","duplicatePlotIDTrapIDCollectDateQF"),
flag_cols = c("duplicatePlotIDTrapIDCollectDateQF"),
fileName = "beetles")
wdir <- 'C:/Users/cflagg/Documents/Test/atbd_output_test'
myPathToGraphics <- paste(wdir,'graphics', sep='/')
myPathToData <- paste(wdir,'data', sep='/')
myPathToCIFiles <- paste(myPathToData, 'CI_files', sep='/')
inFieldData <- read.csv(paste(myPathToData, 'ExampleBeetle_FieldData.csv', sep='/'), stringsAsFactors=FALSE)
inFieldData <- rbind(inFieldData[1,],inFieldData) # No duplicates exist, need to introduce an error to the input dataset
pubFieldData <- gen_concatenatedVal(df=inFieldData, cols=c("plotID", "trapID", "collectDate"), separator=".", newColName="eventID")
names(inFieldData)
inFieldData$X
paste(paste(myPathToCIFiles,"deetles"))
paste(paste(myPathToCIFiles,"deetles", sep = "/"))
paste(paste(myPathToCIFiles,"deetles", sep = "/"),"_df")
paste(paste(myPathToCIFiles,"deetles", sep = "/"),"_df",sep="")
# error_filter(flag), golden_filter(flag)
gen_outputFiles <- function(golden_df,error_df, pub_cols, added_cols, flag_cols, fileName){
browser()
require(dplyr)
# these variables convert column names into integer positions
addedNum <- match(added_cols, names(error_df)) # columns to be removed from input
colNums <- match(pub_cols, names(error_df)) # feed pub column column positions for error_output
flagNums <- match(flag_cols, names(error_df)) # column with flags
colNums2 <- match(pub_cols, names(golden_df)) # feed pub column positions for golden_output
paths <- paste(myPathToCIFiles,fileName,sep="/")
# for all columns - input files that 1) have errors (errorInput) and 2) have no errors (goldenInput)
# file 1: dump flagging column - this needs to dump the added eventID and flag columns
select(error_df, -addedNum) %>% write.csv(file = paste(paths,"_errorInput.csv",sep=""),
row.names = FALSE,na='', fileEncoding='UTF-8') # error_input
# file 2: golden_input, no error rows, all columns except for added columns
select(golden_df, -addedNum) %>% write.csv(file = paste(paths,"_goldenInput.csv",sep=""),
row.names = FALSE,na='',fileEncoding='UTF-8') # golden_input
# for specific columns
# file 3: error_output/pub_flags - this file needs the flag column
select(error_df, colNums, flagNums) %>% write.csv(file = paste(paths,"_pubFlags.csv",sep=""),
row.names = FALSE,na='', fileEncoding='UTF-8') # pub_flags (error_output)
# file 4: golden_output
select(golden_df,colNums2) %>% write.csv(file = paste(paths,"_pubNoFlags.csv",sep=""),
row.names = FALSE,na='',fileEncoding='UTF-8') # pub_noFlags (golden_output)
}
paste(paste(myPathToCIFiles,"deetles", sep = "/"),"_df",sep="")
inFieldData <- read.csv(paste(myPathToData, 'ExampleBeetle_FieldData.csv', sep='/'), stringsAsFactors=FALSE)
# No duplicates exist, need to introduce an error to the input dataset
inFieldData <- rbind(inFieldData[1,],inFieldData)
# create pub_output data frame - generate eventID
pubFieldData <- gen_concatenatedVal(df=inFieldData, cols=c("plotID", "trapID", "collectDate"), separator=".", newColName="eventID")
# flag duplicate rows - overwrite ERROR data frame
inFieldData <- flag_dups(pubFieldData,cols=c("plotID", "trapID", "collectDate"))
# remove duplicates from pub_output - this is a specific function that does not flag duplicate rows, simply removes
pubFieldData <- rem_dups(df=pubFieldData, cols=c("plotID", "trapID", "collectDate"))
# write output files
gen_outputFiles(golden_df = pubFieldData,
error_df = inFieldData,
pub_cols = c("siteID","plotID","eventID"),
added_cols = c("X","eventID","duplicatePlotIDTrapIDCollectDateQF"),
flag_cols = c("duplicatePlotIDTrapIDCollectDateQF"),
fileName = "beetles")
? rem_allButGreatest()
? flag_dups
gen_outputFiles(golden_df = pubFieldData,
error_df = inFieldData,
pub_cols = c(1:3),
added_cols = c(18:19),
flag_cols = c(19),
fileName = "beetles")
# error_filter(flag), golden_filter(flag)
gen_outputFiles <- function(golden_df,error_df, pub_cols, rem_cols, flag_cols, fileName){
require(dplyr)
# these variables convert column names into integer positions
addedNum <- match(rem_cols, names(error_df)) # columns to be removed from input
colNums <- match(pub_cols, names(error_df)) # feed pub column column positions for error_output
flagNums <- match(flag_cols, names(error_df)) # column with flags
colNums2 <- match(pub_cols, names(golden_df)) # feed pub column positions for golden_output
paths <- paste(myPathToCIFiles,fileName,sep="/") # concatenate file name and folder path
# for all columns - input files that 1) have errors (error_input) and 2) have no errors (golden_input)
# file 1: dump flagging column - this needs to dump the added eventID and flag columns
select(error_df, -addedNum) %>% write.csv(file = paste(paths,"_errorInput.csv",sep=""),
row.names = FALSE,na='', fileEncoding='UTF-8') # error_input
# file 2: golden_input, no error rows, all columns except for added columns
select(golden_df, -addedNum) %>% write.csv(file = paste(paths,"_goldenInput.csv",sep=""),
row.names = FALSE,na='',fileEncoding='UTF-8') # golden_input
# for specific columns
# file 3: error_output/pub_flags - this file needs the flag column
select(error_df, colNums, flagNums) %>% write.csv(file = paste(paths,"_pubFlags.csv",sep=""),
row.names = FALSE,na='', fileEncoding='UTF-8') # pub_flags (error_output)
# file 4: golden_output, this is what would be pushed to the data portal
select(golden_df,colNums2) %>% write.csv(file = paste(paths,"_pubNoFlags.csv",sep=""),
row.names = FALSE,na='',fileEncoding='UTF-8') # pub_noFlags (golden_output)
# Description: generates four .csv files for CI: two files used as inputs for processing (one with errors, one without errors)
# and two files that represent the 'ideal' publication outputs (one with errors flagged, one that has errors removed).
# These four files are generated from two input data frames. One data frame should have all rows and columns present with quality flags.
# The other data frame should have only error free rows and columns. User must tell the function which columns are "added" e.g.
# columns that have been derived from other columns (i.e. a concatenated eventID), what columns represent quality flags, and which
# columns should be kept for publication outputs.
# Author: Cody Flagg, 7/1/2015
}
# write output files
gen_outputFiles(golden_df = pubFieldData,
error_df = inFieldData,
pub_cols = c("siteID","plotID","eventID"),
rem_cols = c("X","eventID","duplicatePlotIDTrapIDCollectDateQF"),
flag_cols = c("duplicatePlotIDTrapIDCollectDateQF"),
fileName = "beetles")
# write output files
gen_outputFiles(golden_df = pubFieldData,
error_df = inFieldData,
pub_cols = c(1:3),
rem_cols = c(18:19),
flag_cols = c(19),
fileName = "beetles")
# update atbdLibrary
library(devtools)
install_github("NEONInc/devTOS",
subdir="atbdLibrary",
auth_user="cflagg",
auth_token = "1a2b3935a35e98cfe2623a544d7bcdb9967d7241")
# update atbdLibrary
library(devtools)
install_github("NEONInc/devTOS",
subdir="atbdLibrary",
auth_user="cflagg",
auth_token = "1a2b3935a35e98cfe2623a544d7bcdb9967d7241")
.GlobalEnv
? .GlobalEnv
library(atbdLibrary)
library(atbdLibrary)
gen_outputFiles()
example("gen_outputFiles")
wdir <- 'C:/Users/cflagg/Documents/Test/atbd_output_test'
myPathToGraphics <- paste(wdir,'graphics', sep='/')
myPathToData <- paste(wdir,'data', sep='/')
myPathToCIFiles <- paste(myPathToData, 'CI_files', sep='/')
```
inFieldData <- read.csv(paste(myPathToData, 'ExampleBeetle_FieldData.csv', sep='/'), stringsAsFactors=FALSE)
inFieldData <- rbind(inFieldData[1,],inFieldData) # No duplicates exist, need to introduce an error to the input dataset
pubFieldData <- gen_concatenatedVal(df=inFieldData, cols=c("plotID", "trapID", "collectDate"), separator=".", newColName="eventID")
inFieldData <- flag_dups(pubFieldData,cols=c("plotID", "trapID", "collectDate"))
gen_exampleTable(df=pubFieldData, startRow=1, endRow=5, cols=c("plotID", "trapID", "collectDate"),cap = "")
pubFieldData <- rem_dups(df=pubFieldData, cols=c("plotID", "trapID", "collectDate"))
gen_exampleTable(df=pubFieldData, startRow=1, endRow=5, cols=c("plotID", "trapID", "collectDate"),cap = "")
gen_outputFiles(golden_df = pubFieldData,
error_df = inFieldData,
pub_cols = c("siteID","plotID","eventID"),
rem_cols = c(18:20),
fileName = "beetles")
names(inFieldData)
gen_outputFiles(golden_df = pubFieldData,
error_df = inFieldData,
pub_cols = c("siteID","plotID","eventID"),
flag_cols = c("duplicatePlotIDTrapIDCollectDateQF")
rem_cols = c(18:20),
fileName = "beetles")
gen_outputFiles(golden_df = pubFieldData,
error_df = inFieldData,
pub_cols = c("siteID","plotID","eventID"),
flag_cols = c("duplicatePlotIDTrapIDCollectDateQF"),
rem_cols = c(18:20),
fileName = "beetles")
? gen_outputFiles
# error_filter(flag), golden_filter(flag)
gen_outputFiles <- function(golden_df,error_df, pub_cols, rem_cols, flag_cols, fileName, pathdir = myPathToCIFiles){
require(dplyr)
# these variables convert column names into integer positions
addedNum <- match(rem_cols, names(error_df)) # columns to be removed from input
colNums <- match(pub_cols, names(error_df)) # feed pub column column positions for error_output
flagNums <- match(flag_cols, names(error_df)) # column with flags
colNums2 <- match(pub_cols, names(golden_df)) # feed pub column positions for golden_output
paths <- paste(pathdir,fileName,sep="/") # concatenate file name and folder path
# for all columns - input files that 1) have errors (error_input) and 2) have no errors (golden_input)
# file 1: dump flagging column - this needs to dump the added eventID and flag columns
select(error_df, -addedNum) %>% write.csv(file = paste(paths,"_errorInput.csv",sep=""),
row.names = FALSE,na='', fileEncoding='UTF-8') # error_input
# file 2: golden_input, no error rows, all columns except for added columns
select(golden_df, -addedNum) %>% write.csv(file = paste(paths,"_goldenInput.csv",sep=""),
row.names = FALSE,na='',fileEncoding='UTF-8') # golden_input
# for specific columns
# file 3: error_output/pub_flags - this file needs the flag column
select(error_df, colNums, flagNums) %>% write.csv(file = paste(paths,"_pubFlags.csv",sep=""),
row.names = FALSE,na='', fileEncoding='UTF-8') # pub_flags (error_output)
# file 4: golden_output, this is what would be pushed to the data portal
select(golden_df,colNums2) %>% write.csv(file = paste(paths,"_pubNoFlags.csv",sep=""),
row.names = FALSE,na='',fileEncoding='UTF-8') # pub_noFlags (golden_output)
# Description: generates four .csv files for CI: two files used as inputs for processing (one with errors, one without errors)
# and two files that represent the 'ideal' publication outputs (one with errors flagged, one that has errors removed).
# These four files are generated from two input data frames. One data frame should have all rows and columns present with quality flags.
# The other data frame should have only error free rows and columns. User must tell the function which columns are "added" e.g.
# columns that have been derived from other columns (i.e. a concatenated eventID), what columns represent quality flags, and which
# columns should be kept for publication outputs.
# Author: Cody Flagg, 7/1/2015
}
gen_outputFiles(golden_df = pubFieldData,
error_df = inFieldData,
pub_cols = c("siteID","plotID","eventID"),
flag_cols = c("duplicatePlotIDTrapIDCollectDateQF"),
rem_cols = c(18:20),
fileName = "beetles")
bet_field
getwd()
library(RJDBC)
drv <- JDBC("org.postgresql.Driver", "C:/sql_workbench/postgresql-8.4-703.jdbc4.jar")
# drv <- JDBC("org.postgresql.Driver", "C:/sql_workbench/postgresql-9.3-1102.jdbc4.jar") # also works
conn <- dbConnect (drv, "jdbc:postgresql://10.100.148.32:5432/dodobase", "fsu", "fsurocks")
tlist<-dbGetTables(conn) # gives the list of things in the dodobase
# test query - from a different table
test2 <- dbGetQuery(conn, "SELECT tag_id
FROM mammals_neon.rmnp_2012_captures
WHERE ear_tag_replaced
Is Not Null")
head(test2)
soil_biomass2 <- dbReadTable(conn, "biomass_neon.soil_pit_biomass2") # updated data with no replicates
soil_biomass2
names(soil_biomass2)
soil_biomass2$horizon
soil_biomass <- dbReadTable(conn, "biomass_neon.soil_pit_biomass")
soil_biomass$horizon
soil_biomass2[c(650:665),]
nrow(soil_biomass2)
? step
setwd("C:Users\cflagg\Documents\GitHub\AvalonSoilProject")
setwd("C:Users/cflagg/Documents/GitHub/AvalonSoilProject")
getwd()
setwd("~/GitHub/AvalonSoilProject")
df <- read.csv("soil_pit_data.csv")
df <- read.csv("~/GitHub/AvalonSoilProject/data/old_data/soildata.csv")
beta <- nlsList(root_prop_of_total ~ 1-B^(depth) | site_id, start = list(B=0.9),
data = subset(df, select=c(site_id, profile, depth, root_prop_of_total)))
library(lattice)
library(nlme)
library(MASS)
beta <- nlsList(root_prop_of_total ~ 1-B^(depth) | site_id, start = list(B=0.9),
data = subset(df, select=c(site_id, profile, depth, root_prop_of_total)))
beta
beta <- nlsList(root_prop_of_total ~ 1-B^(depth) | site_id | profile, start = list(B=0.9),
data = subset(df, select=c(site_id, profile, depth, root_prop_of_total)))
beta <- nlsList(root_prop_of_total ~ 1-B^(depth) | site_id/profile, start = list(B=0.9),
data = subset(df, select=c(site_id, profile, depth, root_prop_of_total)))
beta
beta
nrow(df)
xyplot(depth ~  root_prop_of_total| site_id, data=df, ylab = "soil depth from surface (cm)", xlab = "cumulative root fraction (Y)", main = "biomass at depth for 29 NEON sites", layout =c(6,5), ylim = c(200,0), pch = 16, col =1,
panel.xyplot(root_prop_total, depth, ...),
beta <- nlsList(root_prop_of_total ~ 1-B^(depth) | site_id, start = list(B=0.9), data = subset(df, select=c(site_id, profile, depth, root_prop_of_total))),
model <- nlme(root_prop_of_total ~ 1-B^(depth) | site_id, model = "ML",  data =subset(df, select=c(site_id, profile, depth, root_prop_of_total)), groups = site_id)
panel=panel.superpose(beta, panel.groups=function(beta)){
limits <- seq(0, 200)
line <- lines(limits, predict(beta), data.frame(x=limits))
fit.fun <- function(lines)predict(beta)
panel.curve(fit.fun)})
beta <- nlsList(root_prop_of_total ~ 1-B^(lower_depth) | site_id/profile, start = list(B=0.9),
data = subset(df, select=c(site_id, profile, depth, root_prop_of_total)))
beta <- nlsList(root_prop_of_total ~ 1-B^(lower_depth) | site_id/profile, start = list(B=0.9),
data = subset(df, select=c(site_id, profile, lower_depth, root_prop_of_total)))
beta
beta <- nlsList(root_prop_of_total ~ 1-B^(depth) | site_id/profile, start = list(B=0.9),
data = subset(df, select=c(site_id, profile, depth, root_prop_of_total)))
beta
xyplot(depth ~  root_prop_of_total| site_id, data=df)
